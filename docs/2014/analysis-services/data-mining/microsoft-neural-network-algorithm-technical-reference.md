---
title: Microsoft ニューラル ネットワーク アルゴリズム テクニカル リファレンス |Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- HIDDEN_NODE_RATIO parameter
- MAXIMUM_INPUT_ATTRIBUTES parameter
- HOLDOUT_PERCENTAGE parameter
- neural network algorithms [Analysis Services]
- output layer [Data Mining]
- neural networks
- MAXIMUM_OUTPUT_ATTRIBUTES parameter
- MAXIMUM_STATES parameter
- SAMPLE_SIZE parameter
- hidden layer
- hidden neurons
- input layer [Data Mining]
- activation function [Data Mining]
- Back-Propagated Delta Rule network
- neural network model [Analysis Services]
- coding [Data Mining]
- HOLDOUT_SEED parameter
ms.assetid: b8fac409-e3c0-4216-b032-364f8ea51095
author: minewiskan
ms.author: owend
manager: craigg
ms.openlocfilehash: 94c36ba87310c5dc86b7a1f70efab5a3ef97bf61
ms.sourcegitcommit: 3026c22b7fba19059a769ea5f367c4f51efaf286
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/15/2019
ms.locfileid: "66083858"
---
# <a name="microsoft-neural-network-algorithm-technical-reference"></a>Microsoft Neural Network Algorithm Technical Reference
  [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワークでは、最大 3 層のニューロンまたは *パーセプトロン* で構成される *多層パーセプトロン*ネットワーク ( *バックプロパゲーション デルタ ルール ネットワーク*とも呼ばれる) を使用します。 これらの層は、入力層、オプションの非表示層、および出力層です。  
  
 多層パーセプトロン ニューラル ネットワークの詳細については、このマニュアルでは扱いません。 このトピックでは、入力値および出力値を正規化するために使用する方法や属性のカーディナリティを減らすために使用する機能選択方法など、アルゴリズムの基本的な実装について説明します。 このトピックでは、アルゴリズムの動作をカスタマイズするために使用できるパラメーターおよびその他の設定について説明します。モデルのクエリに関する追加情報へのリンクも示します。  
  
## <a name="implementation-of-the-microsoft-neural-network-algorithm"></a>Microsoft ニューラル ネットワーク アルゴリズムの実装  
 多層パーセプトロン ニューラル ネットワークでは、各ニューロンは 1 つまたは複数の入力を受け取り、1 つまたは複数の同一の出力を生成します。 各出力は、ニューロンへの入力の合計の単純な非線形関数です。 入力は入力層のノードから非表示層のノードに送られ、次に非表示層から出力層に渡されます。層内のニューロン間は接続されていません。 ロジスティック回帰モデルのように、非表示層が含まれていない場合、入力は入力層のノードから出力層のノードに直接渡されます。  
  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムで作成されるニューラル ネットワークには、次の 3 種類のニューロンがあります。  
  
-   `Input neurons`  
  
 入力ニューロンは、データ マイニング モデルの入力属性値を指定します。 不連続の入力属性の場合、入力ニューロンは通常、入力属性からの 1 つの状態を表します。 この状態には不足値が含まれます。状態が不足値になるのは、属性のトレーニング データに NULL が含まれている場合です。 3 つ以上の状態を持つ不連続の入力属性では、各状態の入力ニューロンが 1 つずつ生成されます。また、トレーニング データに NULL が含まれている場合は、存在しない状態の入力ニューロンが 1 つ生成されます。 連続する入力属性では、存在しない状態のニューロンと、連続する属性自体の値のニューロンという 2 つの入力ニューロンが生成されます。 入力ニューロンは、1 つまたは複数の非表示ニューロンの入力になります。  
  
-   `Hidden neurons`  
  
 非表示ニューロンは入力ニューロンから入力を受け取り、出力ニューロンに出力を渡します。  
  
-   `Output neurons`  
  
 出力ニューロンは、データ マイニング モデルの予測可能属性値を表します。 不連続の入力属性の場合、出力ニューロンは通常、欠落値などの予測可能属性の 1 つの予測状態を表します。 たとえば、バイナリの予測可能属性では、存在しない状態または存在する状態を表す 1 つの出力ノードが生成され、その属性の値が存在するかどうかが示されます。 予測可能属性として使用されるブール型の列では、true 値のニューロン、false 値のニューロン、および存在しない状態または存在する状態のニューロンという 3 つの出力ニューロンが生成されます。 3 つ以上の状態を持つ不連続の予測可能属性では、各状態の出力ニューロンと、存在しない状態または存在する状態の出力ニューロンが 1 つずつ生成されます。 連続する予測可能な列では、存在しない状態または存在する状態のニューロンと、連続する列自体の値のニューロンという 2 つの出力ニューロンが生成されます。 予測可能な列のセットを確認することによって 500 を超える出力ニューロンが生成された場合は、 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] によって追加の出力ニューロンを表す新しいネットワークがマイニング モデル内に生成されます。  
  
 ニューロンは、どのネットワーク層に含まれているかに応じて、他のニューロンまたは他のデータから入力を受け取ります。 入力ニューロンでは、元のデータからの入力を受け取ります。 非表示ニューロンと出力ニューロンは、ニューラル ネットワーク内の他のニューロンの出力からの入力を受け取ります。 入力によってニューロン間のリレーションシップが確立され、特定のケース セットを分析するためのパスとしての役割を果たします。  
  
 各入力には、 *重み*と呼ばれる値が割り当てられています。この値は、非表示ニューロンまたは出力ニューロンに対する特定の入力の関連性または重要性を表します。 入力に割り当てられている重みが大きいほど、その入力の値の関連性または重要性が増加します。 重みには負の値も使用できます。これは、その入力によって特定のニューロンがアクティブになるのではなく、抑制されることを意味します。 特定のニューロンに対する入力の重要性を増加させるには、各入力の値と重みを乗算します。 負の重みの場合は、値と重みを乗算すると重要性が低下します。  
  
 各ニューロンには *アクティブ化関数*と呼ばれる単純な非線形関数が割り当てられており、ニューラル ネットワークの層に対する特定のニューロンの関連性または重要性が表されます。 非表示ニューロンではアクティブ化関数として *ハイパーボリック タンジェント* 関数 () を使用し、出力ニューロンではアクティブ化関数として *シグモイド* 関数を使用します。 どちらの関数も、ニューラル ネットワークによる入力ニューロンと出力ニューロン間の非線形リレーションシップのモデル化を可能にする非線形の連続関数です。  
  
### <a name="training-neural-networks"></a>ニューラル ネットワークのトレーニング  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムを使用するデータ マイニング モデルのトレーニングには、複数の手順が必要です。 これらの手順は、アルゴリズム パラメーターに対して指定した値の影響を強く受けます。  
  
 まず、アルゴリズムによってデータ ソースのトレーニング データの評価および抽出が行われます。 *予約データ*と呼ばれるトレーニング データの割合は、ネットワークの精度の評価で使用するために予約されています。 トレーニング処理の間、トレーニング データを反復処理するたびに、ネットワークが即座に評価されます。 精度が向上しなくなると、トレーニング処理が停止します。  
  
 *SAMPLE_SIZE* パラメーターと *HOLDOUT_PERCENTAGE* パラメーターの値は、トレーニング データからサンプリングするケースの数と、予約データに対して使用しないケースの数を決めるために使用します。 *HOLDOUT_SEED* パラメーターの値は、予約データに対して使用しない個々のケースをランダムに決定するために使用します。  
  
> [!NOTE]  
>  これらのアルゴリズム パラメーターは、テスト データ セットを定義するためにマイニング構造に適用される HOLDOUT_SIZE プロパティおよび HOLDOUT_SEED プロパティとは異なります。  
  
 次に、マイニング モデルがサポートするネットワークの数と複雑さがアルゴリズムによって決定されます。 予測のみに使用される 1 つまたは複数の属性がマイニング モデルに含まれている場合は、そのようなすべての属性を表す単一のネットワークが作成されます。 入力と予測に使用される 1 つまたは複数の属性がマイニング モデルに含まれている場合は、アルゴリズム プロバイダーによって各属性のネットワークが作成されます。  
  
 不連続の値を持つ入力属性および予測可能属性の場合、各入力ニューロンまたは出力ニューロンはそれぞれ 1 つの状態を表します。 連続する値を持つ入力属性および予測可能属性の場合、各入力ニューロンまたは出力ニューロンはそれぞれ属性の値の範囲および分布を表します。 両方のケースでサポートされる状態の最大数は、 *MAXIMUM_STATES* アルゴリズム パラメーターの値によって異なります。 特定の属性の状態の数が *MAXIMUM_STATES* アルゴリズム パラメーターの値を超えている場合は、許可された状態の最大数に達するまで、その属性の最も一般的な状態または最も関連性の強い状態が選択され、残りの状態は分析の目的では不足値としてグループ化されます。  
  
 アルゴリズムでは、非表示層に対して作成するニューロンの最初の数を決定するときに *HIDDEN_NODE_RATIO* パラメーターの値が使用されます。 *HIDDEN_NODE_RATIO* を 0 に設定すると、マイニング モデルに対して生成されるネットワーク内に非表示層が作成されず、ニューラル ネットワークがロジスティック回帰として扱われます。  
  
 アルゴリズム プロバイダーでは、 *一括学習*と呼ばれる処理で、以前に予約されたトレーニング データのセットを取得し、予約データ内の各ケースの実際の既知の値をネットワークの予測と比較することによって、ネットワーク内のすべての入力の重みを同時に反復的に評価します。 アルゴリズムによってトレーニング データのセット全体が評価された後、各ニューロンの予測値と実際値が確認されます。 アルゴリズムでは、エラーがあればエラーの程度を計算し、 *バックプロパゲーション*と呼ばれる処理で出力ニューロンから入力ニューロンに逆方向の処理を行い、そのニューロンの入力に関連付けられた重みを調整します。 次に、アルゴリズムではトレーニング データのセット全体で処理が繰り返されます。 アルゴリズムでは多数の重みと出力ニューロンをサポートできるので、入力の重みの割り当ておよび評価を行うトレーニング処理の実行には、共役勾配アルゴリズムが使用されます。 共役勾配アルゴリズムの詳細については、このマニュアルでは扱いません。  
  
### <a name="feature-selection"></a>機能の選択  
 入力属性の数が *MAXIMUM_INPUT_ATTRIBUTES* パラメーターの値を上回っているか、予測可能属性の数が *MAXIMUM_OUTPUT_ATTRIBUTES* パラメーターの値を上回っている場合は、マイニング モデルに含まれているネットワークの複雑さを軽減するために、機能選択アルゴリズムが使用されます。 機能選択によって、入力属性または予測可能属性の数が、モデルとの関連性が統計的に最も高い属性の数まで減らされます。  
  
 すべての [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] データ マイニング アルゴリズムでは、分析の向上と処理負荷の削減のため、機能の選択が自動的に使用されます。 ニューラル ネットワーク モデルの機能の選択に使用される方法は、属性のデータ型に応じて異なります。 参考に、ニューラル ネットワーク モデルで使用される機能の選択の方法と、ニューラル ネットワーク アルゴリズムに基づくロジスティック回帰アルゴリズムで使用される機能の選択の方法を次の表に示します。  
  
|アルゴリズム|分析の方法|コメント|  
|---------------|------------------------|--------------|  
|ニューラル ネットワーク|興味深さのスコア<br /><br /> Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|ニューラル ネットワーク アルゴリズムでは、データに連続列が含まれている限り、エントロピに基づくスコアリング方法とベイズ スコアリング方法の両方を使用できます。<br /><br /> 既定値です。|  
|ロジスティック回帰|興味深さのスコア<br /><br /> Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|このアルゴリズムでは、機能の選択の動作を制御するパラメーターを渡すことができないため、既定値が使用されます。 したがって、すべての属性が不連続属性または分離された属性の場合は、既定値は BDEU です。|  
  
 ニューラル ネットワーク モデルに対する機能の選択を制御するアルゴリズム パラメーターは、MAXIMUM_INPUT_ATTRIBUTES、MAXIMUM_OUTPUT_ATTRIBUTES、および MAXIMUM_STATES です。 HIDDEN_NODE_RATIO パラメーターを設定して、非表示層の数を制御することもできます。  
  
### <a name="scoring-methods"></a>スコアリング方法  
 *スコアリング* は正規化の一種であり、ニュートラル ネットワーク モデルのトレーニングのコンテキストでは、不連続テキスト ラベルなどの値を、他の種類の入力との比較およびネットワーク内での重み付けを行うことができる値に変換するプロセスを意味します。 たとえば、Male および Female という値をとる Gender という入力属性と、可変値をとる Income という入力属性があるとします。この場合、各属性の値を直接比較することはできません。そのため、値を共通のスケールにエンコードして、重みを計算できるようにする必要があります。 スコアリングは、このような入力を数値 (特に確率範囲) に正規化するプロセスです。 正規化に使用する関数は、極端な値によって分析結果が歪められることがないように、入力値を単一のスケールでより均等に分布させる場合にも役立ちます。  
  
 ニューラル ネットワークの出力もエンコードされます。 出力 (予測) に使用するターゲットが 1 つだけ存在する場合、または入力用ではなく予測のみに使用するターゲットが複数存在する場合、モデルは単一のネットワークを作成するため、値を正規化する必要はないと思われるかもしれません。 しかし、複数の属性が入力および予測に使用される場合、モデルは複数のネットワークを作成する必要があります。したがって、すべての値を正規化し、出力についてもネットワークからの出力時にエンコードする必要があります。  
  
 入力のエンコードは、トレーニング ケース内の各不連続値を合計した値とその重みの乗算を基にしています。 これは *加重和*と呼ばれます。加重和は非表示層のアクティブ化関数に渡されます。 次に示すように、エンコードには z スコアが使用されます。  
  
 **不連続値**  
  
 Μ = p - 状態の前の確率  
  
 StdDev  = sqrt(p(1-p))  
  
 **連続値**  
  
 値が存在する 1 - μ/σ を =  
  
 値が存在しない = - μ/σ  
  
 値のエンコードが完了したら、ネットワーク エッジを重みとして使用して入力を加重合計します。  
  
 出力のエンコードには、シグモイド関数が使用されます。シグモイド関数は、予測に非常に役立つ性質をいくつか備えています。 このような性質の 1 つとして、元の値のスケーリング方法や値が負であるか正であるかにかかわらず、常に 0 ～ 1 の値を出力するという点が挙げられます。この性質は確率の推定に適しています。 もう 1 つの有用な性質は、シグモイド関数にはスムージング効果があるため、値が変曲点から離れるにつれて、値の確率が 0 または 1 の方向へ緩やかに移動するという点です。  
  
## <a name="customizing-the-neural-network-algorithm"></a>ニューラル ネットワーク アルゴリズムのカスタマイズ  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムでは、結果として得られるマイニング モデルの動作、パフォーマンス、および精度に影響を与えるいくつかのパラメーターがサポートされています。 列にモデリング フラグを設定するか、または列内の値の処理方法を指定するディストリビューション フラグを設定して、モデルによるデータの処理方法を変更することもできます。  
  
### <a name="setting-algorithm-parameters"></a>アルゴリズム パラメーターの設定  
 次の表は、Microsoft ニューラル ネットワーク アルゴリズムで使用できるパラメーターを示しています。  
  
 HIDDEN_NODE_RATIO  
 入力ニューロンおよび出力ニューロンに対する非表示ニューロンの比率を指定します。 次の式で、非表示層のニューロンの最初の数を求めます。  
  
 HIDDEN_NODE_RATIO * SQRT (入力ニューロンの総数 \* 出力ニューロンの総数)  
  
 既定値は、4.0 です。  
  
 HOLDOUT_PERCENTAGE  
 提示されたエラーの計算に使用するトレーニング データ内のケースの割合を指定します。この割合は、マイニング モデルのトレーニング中に停止条件の一部として使用されます。  
  
 既定値は、30 です。  
  
 HOLDOUT_SEED  
 アルゴリズムが予約データをランダムに調べるときに使用する擬似乱数ジェネレーターのシード値を指定します。 このパラメーターを 0 に設定すると、アルゴリズムによってマイニング モデルの名前に基づいたシードが生成され、再処理中にモデルのコンテンツが変更されることはありません。  
  
 既定値は 0 です。  
  
 MAXIMUM_INPUT_ATTRIBUTES  
 機能選択を採用する前にアルゴリズムに指定できる入力属性の最大数を設定します。 この値を 0 に設定すると、入力属性に対する機能の選択が無効になります。  
  
 既定値は 255 です。  
  
 MAXIMUM_OUTPUT_ATTRIBUTES  
 機能選択を採用する前にアルゴリズムに指定できる出力属性の最大数を設定します。 この値を 0 に設定すると、出力属性に対する機能の選択が無効になります。  
  
 既定値は 255 です。  
  
 MAXIMUM_STATES  
 アルゴリズムによってサポートされる、属性ごとの不連続状態の最大数を指定します。 特定の属性の状態の数がこのパラメーターで指定した数を上回ると、アルゴリズムはその属性の最も一般的な状態を使用し、残りの状態を存在しない状態として扱います。  
  
 既定値は 100 です。  
  
 SAMPLE_SIZE  
 モデルのトレーニングに使用するケースの数を指定します。 アルゴリズムでは、この数と、HOLDOUT_PERCENTAGE パラメーターで指定された予約データに含まれないケースの総数の割合のうち、いずれか小さい方が使用されます。  
  
 たとえば、HOLDOUT_PERCENTAGE が 30 に設定されている場合、アルゴリズムでは、このパラメーターの値と、ケースの総数の 70% に相当する値のうち、いずれか小さい方が使用されます。  
  
 既定値は 10000 です。  
  
### <a name="modeling-flags"></a>ModelingFlags  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムでは、次のモデリング フラグを使用できます。  
  
 NOT NULL  
 列に NULL を含めることはできないことを示します。 モデルのトレーニング中に NULL が検出された場合はエラーが発生します。  
  
 マイニング構造列に適用されます。  
  
 MODEL_EXISTENCE_ONLY  
 属性の値が存在するかどうかだけをモデルで考慮する必要があることを示します。 正確な値かどうかは問題になりません。  
  
 マイニング モデル列に適用されます。  
  
### <a name="distribution-flags"></a>ディストリビューション フラグ  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムでは、次のディストリビューション フラグを使用できます。 ディストリビューション フラグは、モデルのみへのヒントとして使用されます。アルゴリズムでは、異なる分布が検出された場合、ヒントで指定された分布ではなく、検出された分布が使用されます。  
  
 標準  
 列内の値を、正規分布またはガウス分布を表す値として処理する必要があることを示します。  
  
 Uniform  
 列内の値を、均等に分布している値として処理する必要があることを示します。つまり、値の確率はほぼ均等で、値の合計数の関数になります。  
  
 Log Normal  
 列内の値を、 *対数正規* 曲線に従って分布している (値の対数が正規分布している) 値として処理する必要があることを示します。  
  
## <a name="requirements"></a>必要条件  
 線形回帰モデルには、1 つ以上の入力列と 1 つの出力列が必要です。  
  
### <a name="input-and-predictable-columns"></a>入力列と予測可能列  
 [!INCLUDE[msCoName](../../includes/msconame-md.md)] ニューラル ネットワーク アルゴリズムでは、次の表に示す特定の入力列と予測可能列がサポートされています。  
  
|[列]|コンテンツの種類|  
|------------|-------------------|  
|入力属性|Continuous、Cyclical、Discrete、Discretized、Key、Table、Ordered|  
|予測可能な属性|Continuous、Cyclical、Discrete、Discretized、Ordered|  
  
> [!NOTE]  
>  コンテンツの種類 Cyclical および Ordered はサポートされますが、アルゴリズムはこれらを不連続の値として扱い、特別な処理は行いません。  
  
## <a name="see-also"></a>参照  
 [Microsoft ニューラル ネットワーク アルゴリズム](microsoft-neural-network-algorithm.md)   
 [ニューラル ネットワーク モデルのマイニング モデル コンテンツ &#40;Analysis Services - データ マイニング&#41;](mining-model-content-for-neural-network-models-analysis-services-data-mining.md)   
 [ニューラル ネットワーク モデルのクエリ例](neural-network-model-query-examples.md)  
  
  
