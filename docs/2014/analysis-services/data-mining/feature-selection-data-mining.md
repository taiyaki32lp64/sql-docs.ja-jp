---
title: 機能の選択 (データ マイニング) |Microsoft Docs
ms.custom: ''
ms.date: 03/06/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- mining models [Analysis Services], feature selections
- attributes [data mining]
- feature selection algorithms [Analysis Services]
- data mining [Analysis Services], feature selections
- neural network algorithms [Analysis Services]
- naive bayes algorithms [Analysis Services]
- decision tree algorithms [Analysis Services]
- datasets [Analysis Services]
- clustering algorithms [Analysis Services]
- coding [Data Mining]
ms.assetid: b044e785-4875-45ab-8ae4-cd3b4e3033bb
author: minewiskan
ms.author: owend
manager: craigg
ms.openlocfilehash: a1d79bb3810a56e8a1769845131312eab306f223
ms.sourcegitcommit: 3026c22b7fba19059a769ea5f367c4f51efaf286
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 06/15/2019
ms.locfileid: "66084418"
---
# <a name="feature-selection-data-mining"></a>機能の選択 (データ マイニング)
  *機能の選択*はツールと処理と分析のために管理しやすいサイズに入力を減らすために使用できる手法を説明するデータ マイニングでよく使用する用語です。 機能の選択は意味だけでなく*カーディナリティの引き下げ*、つまり、モデルをも意味している属性の選択のビルド時に考慮できる属性の数に、任意または定義済みのカットオフを課すアナリストまたはモデリング ツールのいずれか積極的に、選択または分析のための有用性に基づく属性を破棄します。  
  
 機能の選択を適用できることは、効果的な分析にとって重要です。それは、モデルの作成に必要な情報以上の情報がデータセットに含まれていることがよくあるためです。 たとえば、顧客の特性を説明する 500 列が含まれているデータセットで、一部の列のデータがわずかしかなく、それらをモデルに追加しても得られる利点がかなり少ない場合があります。 不要な列を保持したままモデルを作成すると、トレーニング処理時により多くの CPU リソースとメモリが必要となり、完成したモデルに必要な記憶領域も増大します。  
  
 リソースが問題とならない場合でも、不要な列を削除することをお勧めします。次の理由から、検出されるパターンの品質が低下する可能性があるためです。  
  
-   ノイズになる列や冗長な列が含まれる場合があります。 こうした列が含まれていると、データから意味のあるパターンを見つけるのが困難になります。  
  
-   ほとんどのデータ マイニング アルゴリズムでは、高次元のデータセットで高品質なパターンを検出するにははるかに大きなトレーニング データセットが必要になります。 しかし、ごく小さなトレーニング データしかないデータ マイニング アプリケーションもあります。  
  
 データ ソースの 500 列中、モデルの構築に有用な情報が含まれている列が 50 列のみである場合、それらを単純にモデルから削除することもできますが、機能の選択の技法を使用して最適な機能を自動的に見つけ、統計的に重要でない値を除外することもできます。 機能の選択は、価値の低いデータが多すぎること、または価値の高いデータが少なすぎることという、2 つの問題を解決するために役立ちます。  
  
## <a name="feature-selection-in-analysis-services-data-mining"></a>Analysis Services によるデータ マイニングでの機能の選択  
 通常、機能の選択は [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] で自動的に実行され、各アルゴリズムには、機能の削減を適切に適用する一連の既定の技法が含まれています。 機能の選択は、常にモデルのトレーニングの前に実行されます。これにより、モデルで使用される可能性の高い属性がデータセット内で自動的に選択されます。 ただし、機能の選択の動作に影響を与えるようにパラメーターを手動で設定することもできます。  
  
 一般に機能の選択では、各属性のスコアが計算されて、ベスト スコアの属性のみが選択されます。 トップ スコアのしきい値を調整することもできます。 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] では、これらのスコアを計算するための複数のメソッドを提供しており、モデルに適したメソッドは、次の要因によって異なります。  
  
-   モデルで使用されるアルゴリズム  
  
-   属性のデータ型  
  
-   モデルに設定したパラメーター  
  
 機能の選択は、列の入力、予測可能な属性、または状態に適用されます。 機能の選択のためのスコアリングが完了すると、モデル作成プロセスに含まれ、予測作成に使用できるのは、アルゴリズムが選択した属性と状態のみです。 機能の選択のしきい値に合わない予測属性を選択した場合、その属性は予想作成に使用されますが、予測はモデル内に存在する全体統計のみを基礎とします。  
  
> [!NOTE]  
>  機能の選択が影響するのはモデルで使用される列だけであり、保存されているマイニング構造には影響しません。 マイニング モデルから除外された列も、マイニング構造では引き続き使用できます。また、マイニング構造列のデータはキャッシュされます。  
  
### <a name="definition-of-feature-selection-methods"></a>機能の選択の方法の定義  
 機能の選択を実装するには、使用するデータの種類や、分析のために選択するアルゴリズムに応じて、さまざまな方法があります。 SQL Server Analysis Services には、属性のスコアリングのためによく使用される一般的な方法がいくつか用意されています。 アルゴリズムまたはデータセットで適用される方法は、データ型および列の使用法に依存します。  
  
 " *興味深さ* " のスコアは、非バイナリの連続する数値データを含む列の属性を順位付けして並べ替えるために使用されます。  
  
 "*Shannon のエントロピ* " のスコア、および 2 つの " *ベイズ* " のスコアは、不連続データおよび分離されたデータを含む列で使用できます。 ただし、連続した列がモデルに含まれる場合、一貫性を保つために、すべての入力列の評価に興味深さのスコアが使用されます。  
  
 次のセクションでは、機能の選択の各メソッドについて説明します。  
  
#### <a name="interestingness-score"></a>興味深さのスコア  
 機能が興味深いのは、有用な情報を提供する場合です。 データ マイニング業界が測定するさまざまな方法を開発したための便利な新機能の定義はシナリオによって異なります、*興味深さ*します。 たとえば、*新奇*外れ値を検出はできるが密接に関連するアイテムで興味深い可能性がありますまたは*識別重み*の興味があります分類します。  
  
 SQL Server Analysis Services で使用される興味深さの尺度が*エントロピに基づく*つまりランダムに分布を持つ属性がより高いエントロピ下の情報が利得; そのため、このような属性は、以下のこと面白いね。 次のようにして、特定の属性のエントロピが他のすべての属性のエントロピと比較されます。  
  
 Interestingness(Attribute) = - (m - Entropy(Attribute)) * (m - Entropy(Attribute))  
  
 中心エントロピ (m) は、機能セット全体のエントロピを表します。 対象となる属性のエントロピを中心エントロピから差し引くことにより、その属性が提供する情報の量を評価できます。  
  
 列に非バイナリの連続する数値データが含まれている場合は、常にこのスコアが既定で使用されます。  
  
#### <a name="shannons-entropy"></a>Shannon のエントロピ  
 Shannon のエントロピは、特定の結果に対する確率変数の不確かさを測定します。 たとえばコイン投げのエントロピは、コインが表になる確率の関数として表すことができます。  
  
 Analysis Services では、次の数式を使用して Shannon のエントロピを計算します。  
  
 H(X) = -  P(xi) log(P(xi))  
  
 このスコアリング方法は、不連続属性と分離された属性で使用できます。  
  
#### <a name="bayesian-with-k2-prior"></a>K2 事前分布を指定したベイズ定理  
 Analysis Services には、ベイジアン ネットワークに基づく 2 つの機能選択スコアが用意されています。 ベイジアン ネットワークとは、状態および状態間の遷移の " *有向* " または " *非循環* " のグラフ (常に現在の状態より前にある状態と後にある状態がある、繰り返し (ループ) を含まないグラフ) です。 定義上、ベイジアン ネットワークでは事前知識を使用できます。 ただし、前の状態のうちのどれを使用して後の状態の確率を計算するかという問題が、アルゴリズムのデザイン、パフォーマンス、および精度にとって重要になります。  
  
 ベイジアン ネットワークの学習のための K2 アルゴリズムは、Cooper と Herskovits によって開発されたもので、データ マイニングでよく使用されます。 K2 アルゴリズムは拡張可能で、複数の変数を分析できますが、入力として使用する変数の順序付けが必要とされます。 詳細については、「[ベイジアン ネットワークの学習: 知識と統計データの組み合わせ](https://go.microsoft.com/fwlink/?LinkId=105885)」(Chickering、Geiger、および Heckerman) を参照してください。  
  
 このスコアリング方法は、不連続属性と分離された属性で使用できます。  
  
#### <a name="bayesian-dirichlet-equivalent-with-uniform-prior"></a>均一な事前分布を指定したベイズ ディリクレ等式  
 ベイズ ディリクレ等式 (BDE) スコアも、与えられたデータセットについて、ベイズ解析を使用してネットワークを評価します。 BDE のスコアリング方法は Heckerman によって開発されたもので、Cooper と Herskovits によって開発された BD メトリックに基づいています。 ディリクレ分布は、ネットワークの各変数の条件付き確率を表す多項分布で、学習に役立つ数多くの特性があります。  
  
 均一な事前分布を指定したベイズ ディリクレ等式 (BDEU) の方法では、数学定数を使用して事前状態の固定分布 (均一な分布) が作成されるディリクレ分布の特殊なケースが想定されています。 また尤度等価も想定されているため、データで等価な構造が区別されることを期待できません。 つまり、If A Then B のスコアが If B Then A のスコアと同じ場合、そのデータに基づいて構造を区別することはできず、因果関係を推論できません。  
  
 ベイジアン ネットワークの詳細およびこれらのスコアリング方法の実装の詳細については、「 [ベイジアン ネットワークの学習 : 知識と統計データの組み合わせ](https://go.microsoft.com/fwlink/?LinkId=105885)」を参照してください。  
  
### <a name="feature-selection-methods-used-by-analysis-services-algorithms"></a>Analysis Services のアルゴリズムで使用される機能の選択の方法  
 次の表は、機能の選択をサポートするアルゴリズム、そのアルゴリズムによって使用される機能の選択の方法、および機能の選択の動作を制御するために設定するパラメーターの一覧です。  
  
|アルゴリズム|分析の方法|コメント|  
|---------------|------------------------|--------------|  
|Naive Bayes|Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|Microsoft Naïve Bayes アルゴリズムで使用できる属性は、不連続属性と分離された属性だけです。したがって、興味深さのスコアは使用できません。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft Naive Bayes アルゴリズム テクニカル リファレンス](microsoft-naive-bayes-algorithm-technical-reference.md)」を参照してください。|  
|デシジョン ツリー|興味深さのスコア<br /><br /> Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|非バイナリの連続する値を含む列がある場合は、一貫性を保つため、すべての列に対して興味深さのスコアが使用されます。 それ以外の場合は、既定の機能の選択の方法か、モデルを作成したときに指定した方法が使用されます。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft デシジョン ツリー アルゴリズム テクニカル リファレンス](microsoft-decision-trees-algorithm-technical-reference.md)」を参照してください。|  
|ニューラル ネットワーク|興味深さのスコア<br /><br /> Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|Microsoft ニューラル ネットワーク アルゴリズムでは、データに連続列が含まれている限り、ベイズおよびエントロピに基づく方法の両方を使用できます。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft ニューラル ネットワーク アルゴリズム テクニカル リファレンス](microsoft-neural-network-algorithm-technical-reference.md)」を参照してください。|  
|ロジスティック回帰|興味深さのスコア<br /><br /> Shannon のエントロピー<br /><br /> K2 事前分布を指定したベイズ定理<br /><br /> 均一な事前分布を指定したベイズ ディリクレ等式 (既定値)|Microsoft ロジスティック回帰アルゴリズムは Microsoft ニューラル ネットワーク アルゴリズムに基づいていますが、ロジスティック回帰モデルをカスタマイズして機能の選択動作を制御することはできません。したがって、機能の選択では、常に属性に最も適した方法が既定で使用されます。<br /><br /> すべての属性が不連続属性または分離された属性の場合は、既定値は BDEU です。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft ロジスティック回帰アルゴリズム テクニカル リファレンス](microsoft-logistic-regression-algorithm-technical-reference.md)」を参照してください。|  
|クラスター|興味深さのスコア|Microsoft クラスタリング アルゴリズムでは、不連続なデータまたは分離されたデータを使用できます。 ただし、各属性のスコアは距離として計算され、連続する数値として表現されるため、興味深さのスコアを使用する必要があります。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft クラスタリング アルゴリズム テクニカル リファレンス](microsoft-clustering-algorithm-technical-reference.md)」を参照してください。|  
|線形回帰|興味深さのスコア|Microsoft 線形回帰アルゴリズムでは、連続列のみをサポートするため、使用できるのは興味深さのスコアだけです。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft 線形回帰アルゴリズム テクニカル リファレンス](microsoft-linear-regression-algorithm-technical-reference.md)」を参照してください。|  
|アソシエーション ルール<br /><br /> シーケンス クラスター|使用しない|これらのアルゴリズムでは、機能の選択は実行されません。<br /><br /> ただし、必要に応じてパラメーター MINIMUM_SUPPORT および MINIMUM_PROBABILIITY の値を設定することによって、アルゴリズムの動作を制御し、入力データのサイズを小さくすることができます。<br /><br /> 詳細については、「 [Microsoft アソシエーション アルゴリズム テクニカル リファレンス](microsoft-association-algorithm-technical-reference.md) 」および「 [Microsoft シーケンス クラスタリング アルゴリズム テクニカル リファレンス](microsoft-sequence-clustering-algorithm-technical-reference.md)」を参照してください。|  
|タイム シリーズ。|使用しない|機能の選択は、時系列モデルには適用されません。<br /><br /> このアルゴリズムの詳細については、「 [Microsoft Time Series アルゴリズム テクニカル リファレンス](microsoft-time-series-algorithm-technical-reference.md)」を参照してください。|  
  
## <a name="feature-selection-parameters"></a>機能の選択のパラメーター  
 機能の選択をサポートするアルゴリズムでは、以下のパラメーターを使用して、機能の選択をいつオンにするかを制御できます。 各アルゴリズムには、許可される入力数の既定値がありますが、その既定値をオーバーライドして属性の数を指定できます。 このセクションは、機能の選択を管理するために提供されるパラメーターを示します。  
  
#### <a name="maximum_input_attributes"></a>MAXIMUM_INPUT_ATTRIBUTES  
 *MAXIMUM_INPUT_ATTRIBUTES* パラメーターで指定した数より多い列がモデルにある場合、アルゴリズムでは、計算により無意味であると判断されたすべての列が無視されます。  
  
#### <a name="maximum_output_attributes"></a>MAXIMUM_OUTPUT_ATTRIBUTES  
 同様に、 *MAXIMUM_OUTPUT_ATTRIBUTES* パラメーターで指定した数より多い予測可能列がモデルにある場合、アルゴリズムでは、計算により無意味であると判断されたすべての列が無視されます。  
  
#### <a name="maximum_states"></a>MAXIMUM_STATES  
 モデルに *MAXIMUM_STATES* パラメーターで指定された数より多いケースがある場合、最も一般的でない状態はグループ化され、無視されます。 これらのパラメーターのいずれかが 0 に設定されている場合、機能の選択はオフになり、処理時間とパフォーマンスに影響を及ぼします。  
  
 機能の選択のこれらのメソッドに加え、モデルの "*モデリング フラグ*"、または構造の "*ディストリビューション フラグ*" を設定すると、アルゴリズム機能を改善して重要な属性を識別したり昇格させたりすることができます。 これらの概念の詳細については、「[モデリング フラグ &#40;データ マイニング&#41;](modeling-flags-data-mining.md)」および「[列の分布 &#40;データ マイニング&#41;](column-distributions-data-mining.md)」を参照してください。  
  
## <a name="see-also"></a>参照  
 [マイニング モデルとマイニング構造のカスタマイズ](customize-mining-models-and-structure.md)  
  
  
